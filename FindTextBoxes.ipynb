{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from scipy import ndimage\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from lib.fast_rcnn.config import cfg, cfg_from_file\n",
    "from lib.fast_rcnn.test import _get_blobs\n",
    "from lib.text_connector.detectors import TextDetector\n",
    "from lib.text_connector.text_connect_cfg import Config as TextLineCfg\n",
    "from lib.rpn_msr.proposal_layer_tf import proposal_layer\n",
    "\n",
    "\n",
    "def resize_im(im, scale, max_scale=None):\n",
    "    f = float(scale) / min(im.shape[0], im.shape[1])\n",
    "    if max_scale != None and f * max(im.shape[0], im.shape[1]) > max_scale:\n",
    "        f = float(max_scale) / max(im.shape[0], im.shape[1])\n",
    "    return cv2.resize(im, None, None, fx=f, fy=f, interpolation=cv2.INTER_LINEAR), f\n",
    "\n",
    "#return 4 vertices\n",
    "def text_boxes(img):    \n",
    "    img, scale = resize_im(img, scale=TextLineCfg.SCALE, max_scale=TextLineCfg.MAX_SCALE)\n",
    "    blobs, im_scales = _get_blobs(img, None)\n",
    "    \n",
    "    if cfg.TEST.HAS_RPN:\n",
    "        im_blob = blobs['data']\n",
    "        blobs['im_info'] = np.array(\n",
    "            [[im_blob.shape[1], im_blob.shape[2], im_scales[0]]],\n",
    "            dtype=np.float32)\n",
    "    cls_prob, box_pred = sess.run([output_cls_prob, output_box_pred], feed_dict={input_img: blobs['data']})\n",
    "    rois, _ = proposal_layer(cls_prob, box_pred, blobs['im_info'], 'TEST', anchor_scales=cfg.ANCHOR_SCALES)\n",
    "    \n",
    "    scores = rois[:, 0]\n",
    "    boxe = rois[:, 1:5] / im_scales[0]\n",
    "    textdetector = TextDetector()\n",
    "    boxe = textdetector.detect(boxe, scores[:, np.newaxis], img.shape[:2])  \n",
    "    boxes = []\n",
    "    for box in boxe:\n",
    "        box = [x / scale for x in box]\n",
    "        boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "#return [x, y, w, h]\n",
    "def text_boxes_simple(image):\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "    im_area = image.shape[0] * image.shape[1]\n",
    "    if im_area < 2000000:\n",
    "        kernel = np.ones((15,15), np.uint8)\n",
    "    else:\n",
    "        kernel = np.ones((30,30), np.uint8)\n",
    "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    im2,ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "    thres = 0\n",
    "    thres_y = 0\n",
    "    for i, ctr in enumerate(sorted_ctrs):\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        thres += (w * h)\n",
    "        thres_y += h\n",
    "    thres = thres/len(sorted_ctrs)\n",
    "    thres_y = thres_y/len(sorted_ctrs)\n",
    "    \n",
    "\n",
    "    boxes = []\n",
    "    for i, ctr in enumerate(sorted_ctrs):\n",
    "        box = []\n",
    "        x, y, w, h = cv2.boundingRect(ctr) \n",
    "        area = w * h\n",
    "        if (area > (thres / 20)) and (area < (thres * 10)) and (area < (im_area * 1/3)) and (area > (im_area /100)) and (h < (thres_y * 10)) and (h < (image.shape[0] /4)):\n",
    "            cv2.rectangle(image,(x,y),( x + w, y + h ),(90,0,255),2)\n",
    "            box = [x, y, w, h]\n",
    "            boxes.append(box)\n",
    "    cv2.imwrite(\"result.png\", image)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test text_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-45b9babbee00>:6: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "cfg_from_file('data/text.yml')\n",
    "\n",
    "# init session\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess = tf.Session(config=config)\n",
    "with gfile.FastGFile('data/ctpn.pb', 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "input_img = sess.graph.get_tensor_by_name('Placeholder:0')\n",
    "output_cls_prob = sess.graph.get_tensor_by_name('Reshape_2:0')\n",
    "output_box_pred = sess.graph.get_tensor_by_name('rpn_bbox_pred/Reshape_1:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.376528739929199 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_name = '/home/topica/Desktop/test_hpt7.jpg'\n",
    "img = cv2.imread(im_name)\n",
    "\n",
    "start_time = time.time()\n",
    "boxes= text_boxes(img)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "base_name = im_name.split('/')[-1]\n",
    "color = (255,0,0)\n",
    "start_time = time.time()\n",
    "for box in boxes:\n",
    "    if (box[5]-box[1]) >= (img.shape[0] / 25):\n",
    "        cv2.line(img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, 2)\n",
    "        cv2.line(img, (int(box[0]), int(box[1])), (int(box[4]), int(box[5])), color, 2)\n",
    "        cv2.line(img, (int(box[6]), int(box[7])), (int(box[2]), int(box[3])), color, 2)\n",
    "        cv2.line(img, (int(box[4]), int(box[5])), (int(box[6]), int(box[7])), color, 2)\n",
    "        \n",
    "cv2.imwrite(os.path.join(\"data/results\", base_name), img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test text_boxes_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[171, 341, 720, 64],\n",
       " [175, 291, 727, 42],\n",
       " [180, 242, 454, 42],\n",
       " [183, 171, 392, 53]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('/home/topica/Desktop/test_hpt7.jpg')\n",
    "text_boxes_simple(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
