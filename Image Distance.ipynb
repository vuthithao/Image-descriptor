{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4373420434779372 0.3701709148930568 0.9236111111111112 0.000715792179107666\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.transform import resize\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.misc import imsave\n",
    "from scipy.ndimage import imread\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "##\n",
    "# Globals\n",
    "##\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# specify resized image sizes\n",
    "height = 2**10\n",
    "width = 2**10\n",
    "\n",
    "##\n",
    "# Functions\n",
    "##\n",
    "\n",
    "def get_img(path, norm_size=True, norm_exposure=False):\n",
    "    '''\n",
    "    Prepare an image for image processing tasks\n",
    "    '''\n",
    "    # flatten returns a 2d grayscale array\n",
    "    img = imread(path, flatten=True).astype(int)\n",
    "    # resizing returns float vals 0:255; convert to ints for downstream tasks\n",
    "    if norm_size:\n",
    "        img = resize(img, (height, width), anti_aliasing=True, preserve_range=True)\n",
    "    if norm_exposure:\n",
    "        img = normalize_exposure(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_histogram(img):\n",
    "    '''\n",
    "    Get the histogram of an image. For an 8-bit, grayscale image, the\n",
    "    histogram will be a 256 unit vector in which the nth value indicates\n",
    "    the percent of the pixels in the image with the given darkness level.\n",
    "    The histogram's values sum to 1.\n",
    "    '''\n",
    "    h, w = img.shape\n",
    "    hist = [0.0] * 256\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            hist[img[i, j]] += 1\n",
    "    return np.array(hist) / (h * w) \n",
    "\n",
    "\n",
    "def normalize_exposure(img):\n",
    "    '''\n",
    "    Normalize the exposure of an image.\n",
    "    '''\n",
    "    img = img.astype(int)\n",
    "    hist = get_histogram(img)\n",
    "    # get the sum of vals accumulated by each position in hist\n",
    "    cdf = np.array([sum(hist[:i+1]) for i in range(len(hist))])\n",
    "    # determine the normalization values for each unit of the cdf\n",
    "    sk = np.uint8(255 * cdf)\n",
    "    # normalize each position in the output image\n",
    "    height, width = img.shape\n",
    "    normalized = np.zeros_like(img)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "            normalized[i, j] = sk[img[i, j]]\n",
    "    return normalized.astype(int)\n",
    "\n",
    "\n",
    "def earth_movers_distance(path_a, path_b):\n",
    "    '''\n",
    "    Measure the Earth Mover's distance between two images\n",
    "    @args:\n",
    "    {str} path_a: the path to an image file\n",
    "    {str} path_b: the path to an image file\n",
    "    @returns:\n",
    "    TODO\n",
    "    '''\n",
    "    img_a = get_img(path_a, norm_exposure=True)\n",
    "    img_b = get_img(path_b, norm_exposure=True)\n",
    "    hist_a = get_histogram(img_a)\n",
    "    hist_b = get_histogram(img_b)\n",
    "    return wasserstein_distance(hist_a, hist_b)\n",
    "\n",
    "\n",
    "def structural_sim(path_a, path_b):\n",
    "    '''\n",
    "    Measure the structural similarity between two images\n",
    "    @args:\n",
    "    {str} path_a: the path to an image file\n",
    "    {str} path_b: the path to an image file\n",
    "    @returns:\n",
    "    {float} a float {-1:1} that measures structural similarity\n",
    "      between the input images\n",
    "    '''\n",
    "    img_a = get_img(path_a)\n",
    "    img_b = get_img(path_b)\n",
    "    sim, diff = compare_ssim(img_a, img_b, full=True)\n",
    "    return sim\n",
    "\n",
    "\n",
    "def pixel_sim(path_a, path_b):\n",
    "    '''\n",
    "    Measure the pixel-level similarity between two images\n",
    "    @args:\n",
    "    {str} path_a: the path to an image file\n",
    "    {str} path_b: the path to an image file\n",
    "    @returns:\n",
    "    {float} a float {-1:1} that measures structural similarity\n",
    "      between the input images\n",
    "    '''\n",
    "    img_a = get_img(path_a, norm_exposure=True)\n",
    "    img_b = get_img(path_b, norm_exposure=True)\n",
    "    return np.sum(np.absolute(img_a - img_b)) / (height*width) / 255\n",
    "\n",
    "\n",
    "def sift_sim(path_a, path_b):\n",
    "    '''\n",
    "    Use SIFT features to measure image similarity\n",
    "    @args:\n",
    "    {str} path_a: the path to an image file\n",
    "    {str} path_b: the path to an image file\n",
    "    @returns:\n",
    "    TODO\n",
    "    '''\n",
    "    # initialize the sift feature detector\n",
    "#     orb = cv2.ORB_create()\n",
    "\n",
    "#     # get the images\n",
    "#     img_a = cv2.imread(path_a)\n",
    "#     img_b = cv2.imread(path_b)\n",
    "\n",
    "#     # find the keypoints and descriptors with SIFT\n",
    "#     kp_a, desc_a = orb.detectAndCompute(img_a, None)\n",
    "#     kp_b, desc_b = orb.detectAndCompute(img_b, None)\n",
    "\n",
    "    desc_a = convert_sift(path_a)\n",
    "#     print(desc_a.shape)\n",
    "    desc_b = convert_sift(path_b)\n",
    "\n",
    "    # initialize the bruteforce matcher\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # match.distance is a float between {0:100} - lower means more similar\n",
    "    matches = bf.match(desc_a, desc_b)\n",
    "    similar_regions = [i for i in matches if i.distance < 70]\n",
    "    if len(matches) == 0:\n",
    "        return 0\n",
    "    return len(similar_regions) / len(matches)\n",
    "\n",
    "def convert_sift(path):\n",
    "    # initialize the sift feature detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # get the images\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp, desc = orb.detectAndCompute(img, None)\n",
    "    return desc\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "if __name__ == '__main__':\n",
    "    img_a = '/home/topica/Desktop/anh_test4.jpg'\n",
    "    img_b = '/home/topica/Desktop/anh_test1.png'\n",
    "    # get the similarity values\n",
    "    structural_sim = structural_sim(img_a, img_b)\n",
    "    pixel_sim = pixel_sim(img_a, img_b)\n",
    "    sift_sim = sift_sim(img_a, img_b)\n",
    "    emd = earth_movers_distance(img_a, img_b)\n",
    "    print(structural_sim, pixel_sim, sift_sim, emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b56 0.4067628118300887 0.36775657803404566 1.0 0.00189102441072464\n",
    "test1 0.4067628118300887 0.36775657803404566 1.0 0.00189102441072464\n",
    "bai 0.35435528116248466 0.3931248010373583 1.0 0.002943076193332672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "427-1b 0.2009683167250975 0.08718918445063573 0.9735294117647059 0.0003592967987060547\n",
    "bai_fa 0.05439038742425484 0.4403153587790096 0.7104072398190046 0.0047726258635520935\n",
    "chu1.j 0.03087476570337006 0.29622936622769225 0.6201923076923077 0.0041794925928115845\n",
    "demo_ro 0.03477050764628357 0.24145067252364813 0.9850746268656716 0.0010894611477851868\n",
    "result_demo_rota 0.043052707973911 0.4053676867017559 0.7593360995850622 0.004580199718475342\n",
    "result_hoa.jpg 0.0739527207578048 0.47579478095559513 0.743455497382199 0.005299217998981476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# 2018.01.16 01:11:49 CST\n",
    "# 2018.01.16 01:55:01 CST\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## (1) read\n",
    "img = cv2.imread(\"chu1.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## (2) threshold\n",
    "th, threshed = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)\n",
    "\n",
    "## (3) minAreaRect on the nozeros\n",
    "pts = cv2.findNonZero(threshed)\n",
    "ret = cv2.minAreaRect(pts)\n",
    "\n",
    "(cx,cy), (w,h), ang = ret\n",
    "if w<h:\n",
    "    w,h = h,w\n",
    "    ang += 90\n",
    "\n",
    "## (4) Find rotated matrix, do rotation\n",
    "M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
    "rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## (5) find and draw the upper and lower boundary of each lines\n",
    "hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
    "\n",
    "th = 2\n",
    "H,W = img.shape[:2]\n",
    "uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
    "lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
    "\n",
    "print(len(uppers))\n",
    "rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2BGR)\n",
    "for y in uppers:\n",
    "    cv2.line(rotated, (0,y), (W, y), (255,0,0), 1)\n",
    "\n",
    "for y in lowers:\n",
    "    cv2.line(rotated, (0,y), (W, y), (0,255,0), 1)\n",
    "\n",
    "cv2.imwrite(\"result.png\", rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#import image\n",
    "image = cv2.imread('/home/topica/Pictures/toan2.png')\n",
    "\n",
    "#grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#binary\n",
    "ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "#dilation\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "#find contours\n",
    "im2,ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#sort contours\n",
    "sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "# print(len(sorted_ctrs))\n",
    "avr_h = 0\n",
    "a = 0\n",
    "for i, ctr in enumerate(sorted_ctrs):\n",
    "    # Get bounding box\n",
    "    x, y, w, h = cv2.boundingRect(ctr)\n",
    "    avr_h += h\n",
    "    a += 1\n",
    "    \n",
    "avr_h = avr_h/a\n",
    "chu = 0\n",
    "for i, ctr in enumerate(sorted_ctrs):\n",
    "    x, y, w, h = cv2.boundingRect(ctr)    \n",
    "    if h >= avr_h/3 and h <= avr_h*3:\n",
    "        cv2.rectangle(image,(x,y),( x + w, y + h ),(90,0,255),2)\n",
    "        chu+=1\n",
    "print(chu)\n",
    "cv2.imshow('marked areas',image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
